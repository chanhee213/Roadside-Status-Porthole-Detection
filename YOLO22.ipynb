{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import xmltodict\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋에 있는 클래스 종류 알아내기 \n",
    "def get_Classes_inImage(xml_file_list):\n",
    "    Classes_inDataSet = []\n",
    "    for xml_file_path in xml_file_list: \n",
    "        f = open(xml_file_path)\n",
    "        xml_file = xmltodict.parse(f.read())\n",
    "        # 사진에 객체가 여러개 있을 경우\n",
    "        try: \n",
    "            for obj in xml_file['annotation']['object']:\n",
    "                Classes_inDataSet.append(obj['name'].lower()) # 들어있는 객체 종류를 알아낸다\n",
    "        # 사진에 객체가 하나만 있을 경우\n",
    "        except TypeError as e: \n",
    "            Classes_inDataSet.append(xml_file['annotation']['object']['name'].lower()) \n",
    "        f.close()\n",
    "    Classes_inDataSet = list(set(Classes_inDataSet))\n",
    "    Classes_inDataSet.sort() # 알파벳 순으로 정렬\n",
    "    return Classes_inDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label data 처리\n",
    "def get_label_fromImage(xml_file_path, Classes_inDataSet):\n",
    "    f = open(xml_file_path)\n",
    "    xml_file = xmltodict.parse(f.read()) \n",
    "    Image_Height = float(xml_file['annotation']['size']['height'])\n",
    "    Image_Width  = float(xml_file['annotation']['size']['width'])\n",
    "    label = np.zeros((7, 7, 25), dtype = float)\n",
    "    try:\n",
    "        for obj in xml_file['annotation']['object']:            \n",
    "            class_index = Classes_inDataSet.index(obj['name'].lower())            \n",
    "            # min, max좌표 얻기\n",
    "            x_min = float(obj['bndbox']['xmin']) \n",
    "            y_min = float(obj['bndbox']['ymin'])\n",
    "            x_max = float(obj['bndbox']['xmax']) \n",
    "            y_max = float(obj['bndbox']['ymax'])\n",
    "            # 224*224에 맞게 변형시켜줌\n",
    "            x_min = float((224.0/Image_Width)*x_min)\n",
    "            y_min = float((224.0/Image_Height)*y_min)\n",
    "            x_max = float((224.0/Image_Width)*x_max)\n",
    "            y_max = float((224.0/Image_Height)*y_max)\n",
    "            # 변형시킨걸 x,y,w,h로 만들기 \n",
    "            x = (x_min + x_max)/2.0\n",
    "            y = (y_min + y_max)/2.0\n",
    "            w = x_max - x_min\n",
    "            h = y_max - y_min\n",
    "            # x,y가 속한 cell알아내기\n",
    "            x_cell = int(x/32) # 0~6\n",
    "            y_cell = int(y/32) # 0~6\n",
    "            # cell의 중심 좌표는 (0.5, 0.5)다\n",
    "            x_val_inCell = float((x - x_cell * 32.0)/32.0) # 0.0 ~ 1.0\n",
    "            y_val_inCell = float((y - y_cell * 32.0)/32.0) # 0.0 ~ 1.0\n",
    "            # w, h 를 0~1 사이의 값으로 만들기\n",
    "            w = w / 224.0\n",
    "            h = h / 224.0\n",
    "            class_index_inCell = class_index + 5\n",
    "            label[y_cell][x_cell][0] = x_val_inCell\n",
    "            label[y_cell][x_cell][1] = y_val_inCell\n",
    "            label[y_cell][x_cell][2] = w\n",
    "            label[y_cell][x_cell][3] = h\n",
    "            label[y_cell][x_cell][4] = 1.0\n",
    "            label[y_cell][x_cell][class_index_inCell] = 1.0\n",
    " # single-object in image\n",
    "    except TypeError as e : \n",
    "        # class의 index 휙득\n",
    "        class_index = Classes_inDataSet.index(xml_file['annotation']['object']['name'].lower())\n",
    "            \n",
    "        # min, max좌표 얻기\n",
    "        x_min = float(xml_file['annotation']['object']['bndbox']['xmin']) \n",
    "        y_min = float(xml_file['annotation']['object']['bndbox']['ymin'])\n",
    "        x_max = float(xml_file['annotation']['object']['bndbox']['xmax']) \n",
    "        y_max = float(xml_file['annotation']['object']['bndbox']['ymax'])\n",
    "\n",
    "        # 224*224에 맞게 변형시켜줌\n",
    "        x_min = float((224.0/Image_Width)*x_min)\n",
    "        y_min = float((224.0/Image_Height)*y_min)\n",
    "        x_max = float((224.0/Image_Width)*x_max)\n",
    "        y_max = float((224.0/Image_Height)*y_max)\n",
    "\n",
    "        # 변형시킨걸 x,y,w,h로 만들기 \n",
    "        x = (x_min + x_max)/2.0\n",
    "        y = (y_min + y_max)/2.0\n",
    "        w = x_max - x_min\n",
    "        h = y_max - y_min\n",
    "\n",
    "        # x,y가 속한 cell알아내기\n",
    "        x_cell = int(x/32) # 0~6\n",
    "        y_cell = int(y/32) # 0~6\n",
    "        x_val_inCell = float((x - x_cell * 32.0)/32.0) # 0.0 ~ 1.0\n",
    "        y_val_inCell = float((y - y_cell * 32.0)/32.0) # 0.0 ~ 1.0\n",
    "        # w, h 를 0~1 사이의 값으로 만들기\n",
    "        w = w / 224.0\n",
    "        h = h / 224.0\n",
    "        class_index_inCell = class_index + 5\n",
    "        label[y_cell][x_cell][0] = x_val_inCell\n",
    "        label[y_cell][x_cell][1] = y_val_inCell\n",
    "        label[y_cell][x_cell][2] = w\n",
    "        label[y_cell][x_cell][3] = h\n",
    "        label[y_cell][x_cell][4] = 1.0\n",
    "        label[y_cell][x_cell][class_index_inCell] = 1.0\n",
    "\n",
    "    return label # np array로 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 사용할 수 있게 처리\n",
    "def make_dataset(image_file_path_list, xml_file_path_list, Classes_inDataSet) :\n",
    "    image_dataset = []\n",
    "    label_dataset = []\n",
    "\n",
    "    for i in tqdm(range(0, len(image_file_path_list)), desc = \"make dataset\"):\n",
    "        image = cv2.imread(image_file_path_list[i]) \n",
    "        image = cv2.resize(image, (224, 224))/ 255.0 # 이미지를 넘파이 배열로 불러온 뒤 255로 나눠 픽셀별 R, G, B를 0~1사이의 값으로 만들어버린다.\n",
    "        label = get_label_fromImage(xml_file_path_list[i], Classes_inDataSet)   \n",
    "        image_dataset.append(image)\n",
    "        label_dataset.append(label)\n",
    "    \n",
    "    image_dataset = np.array(image_dataset, dtype=\"object\")\n",
    "    label_dataset = np.array(label_dataset, dtype=\"object\")\n",
    "    image_dataset = np.reshape(image_dataset, (-1, 224, 224, 3)).astype(np.float32)\n",
    "    label_dataset = np.reshape(label_dataset, (-1, 7, 7, 25))\n",
    "\n",
    "    return image_dataset, tf.convert_to_tensor(label_dataset, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "def yolo_multitask_loss(y_true, y_pred): # 커스텀 손실함수. 배치 단위로 값이 들어온다\n",
    "    # YOLOv1의 Loss function은 3개로 나뉜다. localization, confidence, classification\n",
    "    # localization은 추측한 box랑 ground truth box의 오차\n",
    "    batch_loss = 0\n",
    "    count = len(y_true)\n",
    "    for i in range(0, len(y_true)) :\n",
    "        y_true_unit = tf.identity(y_true[i])\n",
    "        y_pred_unit = tf.identity(y_pred[i])\n",
    "        y_true_unit = tf.reshape(y_true_unit, [49, 25])\n",
    "        y_pred_unit = tf.reshape(y_pred_unit, [49, 30])\n",
    "        loss = 0\n",
    "        \n",
    "        for j in range(0, len(y_true_unit)) :\n",
    "            # pred = [1, 30], true = [1, 25] \n",
    "            bbox1_pred = tf.identity(y_pred_unit[j][:4])\n",
    "            bbox1_pred_confidence = tf.identity(y_pred_unit[j][4])\n",
    "            bbox2_pred = tf.identity(y_pred_unit[j][5:9])\n",
    "            bbox2_pred_confidence = tf.identity(y_pred_unit[j][9])\n",
    "            class_pred = tf.identity(y_pred_unit[j][10:])\n",
    "            bbox_true = tf.identity(y_true_unit[j][:4])\n",
    "            bbox_true_confidence = tf.identity(y_true_unit[j][4])\n",
    "            class_true = tf.identity(y_true_unit[j][5:])\n",
    "            \n",
    "            # IoU 구하기\n",
    "            # x,y,w,h -> min_x, min_y, max_x, max_y로 변환\n",
    "            box_pred_1_np = bbox1_pred.numpy()\n",
    "            box_pred_2_np = bbox2_pred.numpy()\n",
    "            box_true_np   = bbox_true.numpy()\n",
    "            box_pred_1_area = box_pred_1_np[2] * box_pred_1_np[3]\n",
    "            box_pred_2_area = box_pred_2_np[2] * box_pred_2_np[3]\n",
    "            box_true_area   = box_true_np[2]  * box_true_np[3]\n",
    "            box_pred_1_minmax = np.asarray([box_pred_1_np[0] - 0.5*box_pred_1_np[2], box_pred_1_np[1] \n",
    "                                            - 0.5*box_pred_1_np[3], box_pred_1_np[0] \n",
    "                                            + 0.5*box_pred_1_np[2], box_pred_1_np[1] \n",
    "                                            + 0.5*box_pred_1_np[3]])\n",
    "            box_pred_2_minmax = np.asarray([box_pred_2_np[0] - 0.5*box_pred_2_np[2], box_pred_2_np[1] \n",
    "                                            - 0.5*box_pred_2_np[3], box_pred_2_np[0] \n",
    "                                            + 0.5*box_pred_2_np[2], box_pred_2_np[1] \n",
    "                                            + 0.5*box_pred_2_np[3]])\n",
    "            box_true_minmax   = np.asarray([box_true_np[0] - 0.5*box_true_np[2], box_true_np[1] \n",
    "                                            - 0.5*box_true_np[3], box_true_np[0] \n",
    "                                            + 0.5*box_true_np[2], box_true_np[1] \n",
    "                                            + 0.5*box_true_np[3]])\n",
    "            # 곂치는 영역의 (min_x, min_y, max_x, max_y)\n",
    "            InterSection_pred_1_with_true = [max(box_pred_1_minmax[0], box_true_minmax[0]), \n",
    "                                             max(box_pred_1_minmax[1], box_true_minmax[1]), \n",
    "                                             min(box_pred_1_minmax[2], box_true_minmax[2]), \n",
    "                                             min(box_pred_1_minmax[3], box_true_minmax[3])]\n",
    "            InterSection_pred_2_with_true = [max(box_pred_2_minmax[0], box_true_minmax[0]), \n",
    "                                             max(box_pred_2_minmax[1], box_true_minmax[1]), \n",
    "                                             min(box_pred_2_minmax[2], box_true_minmax[2]), \n",
    "                                             min(box_pred_2_minmax[3], box_true_minmax[3])]\n",
    "\n",
    "            # 박스별로 IoU를 구한다\n",
    "            IntersectionArea_pred_1_true = 0\n",
    "\n",
    "            # 음수 * 음수 = 양수일 수도 있으니 검사를 한다.\n",
    "            if (InterSection_pred_1_with_true[2] - InterSection_pred_1_with_true[0] + 1) >= 0 and (\n",
    "                InterSection_pred_1_with_true[3] - InterSection_pred_1_with_true[1] + 1) >= 0 :\n",
    "                    IntersectionArea_pred_1_true = (InterSection_pred_1_with_true[2] - InterSection_pred_1_with_true[0] + 1\n",
    "                                                    ) * InterSection_pred_1_with_true[3] - InterSection_pred_1_with_true[1] + 1\n",
    "\n",
    "            IntersectionArea_pred_2_true = 0\n",
    "\n",
    "            if (InterSection_pred_2_with_true[2] - InterSection_pred_2_with_true[0] + 1) >= 0 and (\n",
    "                InterSection_pred_2_with_true[3] - InterSection_pred_2_with_true[1] + 1) >= 0 :\n",
    "                    IntersectionArea_pred_2_true = (InterSection_pred_2_with_true[2] - InterSection_pred_2_with_true[0] + 1\n",
    "                                                    ) * InterSection_pred_2_with_true[3] - InterSection_pred_2_with_true[1] + 1\n",
    "\n",
    "            Union_pred_1_true = box_pred_1_area + box_true_area - IntersectionArea_pred_1_true\n",
    "            Union_pred_2_true = box_pred_2_area + box_true_area - IntersectionArea_pred_2_true\n",
    "\n",
    "            IoU_box_1 = IntersectionArea_pred_1_true/Union_pred_1_true\n",
    "            IoU_box_2 = IntersectionArea_pred_2_true/Union_pred_2_true\n",
    "                        \n",
    "            responsible_IoU = 0\n",
    "            responsible_box = 0\n",
    "            responsible_bbox_confidence = 0\n",
    "            non_responsible_bbox_confidence = 0\n",
    "\n",
    "            # box1, box2 중 responsible한걸 선택(IoU 기준)\n",
    "            if IoU_box_1 >= IoU_box_2 :\n",
    "                responsible_IoU = IoU_box_1\n",
    "                responsible_box = tf.identity(bbox1_pred)\n",
    "                responsible_bbox_confidence = tf.identity(bbox1_pred_confidence)\n",
    "                non_responsible_bbox_confidence = tf.identity(bbox2_pred_confidence)\n",
    "                                \n",
    "            else :\n",
    "                responsible_IoU = IoU_box_2\n",
    "                responsible_box = tf.identity(bbox2_pred)\n",
    "                responsible_bbox_confidence = tf.identity(bbox2_pred_confidence)\n",
    "                non_responsible_bbox_confidence = tf.identity(bbox1_pred_confidence)\n",
    "                \n",
    "            # 1obj(i) 정하기(해당 셀에 객체의 중심좌표가 들어있는가?)\n",
    "            obj_exist = tf.ones_like(bbox_true_confidence)\n",
    "            if box_true_np[0] == 0.0 and box_true_np[1] == 0.0 and box_true_np[2] == 0.0 and box_true_np[3] == 0.0 : \n",
    "                obj_exist = tf.zeros_like(bbox_true_confidence) \n",
    "            \n",
    "                        \n",
    "            # 만약 해당 cell에 객체가 없으면 confidence error의 no object 파트만 판단. (label된 값에서 알아서 해결)\n",
    "            # 0~3 : bbox1의 위치 정보, 4 : bbox1의 bbox confidence score, 5~8 : bbox2의 위치 정보, 9 : bbox2의 confidence score, 10~29 : cell에 존재하는 클래스 확률 = pr(class | object) \n",
    "\n",
    "            # localization error 구하기(x,y,w,h). x, y는 해당 grid cell의 중심 좌표와 offset이고 w, h는 전체 이미지에 대해 정규화된 값이다. 즉, 범위가 0~1이다.\n",
    "            localization_err_x = tf.math.pow( tf.math.subtract(bbox_true[0], responsible_box[0]), 2) # (x-x_hat)^2\n",
    "            localization_err_y = tf.math.pow( tf.math.subtract(bbox_true[1], responsible_box[1]), 2) # (y-y_hat)^2\n",
    "\n",
    "            localization_err_w = tf.math.pow( tf.math.subtract(tf.sqrt(bbox_true[2]), tf.sqrt(responsible_box[2])), 2) # (sqrt(w) - sqrt(w_hat))^2\n",
    "            localization_err_h = tf.math.pow( tf.math.subtract(tf.sqrt(bbox_true[3]), tf.sqrt(responsible_box[3])), 2) # (sqrt(h) - sqrt(h_hat))^2\n",
    "            \n",
    "            # nan 방지\n",
    "            if tf.math.is_nan(localization_err_w).numpy() == True :\n",
    "                localization_err_w = tf.zeros_like(localization_err_w, dtype=tf.float32)\n",
    "            \n",
    "            if tf.math.is_nan(localization_err_h).numpy() == True :\n",
    "                localization_err_h = tf.zeros_like(localization_err_h, dtype=tf.float32)\n",
    "            \n",
    "            localization_err_1 = tf.math.add(localization_err_x, localization_err_y)\n",
    "            localization_err_2 = tf.math.add(localization_err_w, localization_err_h)\n",
    "            localization_err = tf.math.add(localization_err_1, localization_err_2)\n",
    "            \n",
    "            weighted_localization_err = tf.math.multiply(localization_err, 5.0) # 5.0 : λ_coord\n",
    "            weighted_localization_err = tf.math.multiply(weighted_localization_err, obj_exist) # 1obj(i) 곱하기\n",
    "            \n",
    "            # confidence error 구하기. true의 경우 답인 객체는 1 * ()고 아니면 0*()가 된다. \n",
    "            # index 4, 9에 있는 값(0~1)이 해당 박스에 객체가 있을 확률을 나타낸거다. Pr(obj in bbox)\n",
    "            \n",
    "            class_confidence_score_obj = tf.math.pow(tf.math.subtract(responsible_bbox_confidence, bbox_true_confidence), 2)\n",
    "            class_confidence_score_noobj = tf.math.pow(tf.math.subtract(non_responsible_bbox_confidence, \n",
    "                                                                        tf.zeros_like(bbox_true_confidence)), 2)\n",
    "            class_confidence_score_noobj = tf.math.multiply(class_confidence_score_noobj, 0.5)\n",
    "            \n",
    "            class_confidence_score_obj = tf.math.multiply(class_confidence_score_obj, obj_exist)\n",
    "            class_confidence_score_noobj = tf.math.multiply(class_confidence_score_noobj, \n",
    "                                                            tf.math.subtract(tf.ones_like(obj_exist), obj_exist)) \n",
    "            # 객체가 존재하면 0, 존재하지 않으면 1을 곱합\n",
    "            \n",
    "            class_confidence_score = tf.math.add(class_confidence_score_obj,  class_confidence_score_noobj) \n",
    "            \n",
    "            # classification loss(10~29. 인덱스 10~29에 해당되는 값은 Pr(Classi |Object)이다. 객체가 cell안에 있을 때 해당 객체일 확률\n",
    "            # class_true_oneCell는 진짜 객체는 1이고 나머지는 0일거다. \n",
    "            \n",
    "            tf.math.pow(tf.math.subtract(class_true, class_pred), 2.0) # 여기서 에러\n",
    "            \n",
    "            classification_err = tf.math.pow(tf.math.subtract(class_true, class_pred), 2.0)\n",
    "            classification_err = tf.math.reduce_sum(classification_err)\n",
    "            classification_err = tf.math.multiply(classification_err, obj_exist)\n",
    "\n",
    "            # loss합체\n",
    "            loss_OneCell_1 = tf.math.add(weighted_localization_err, class_confidence_score)\n",
    "            loss_OneCell = tf.math.add(loss_OneCell_1, classification_err)\n",
    "            \n",
    "            if loss == 0 :\n",
    "                loss = tf.identity(loss_OneCell)\n",
    "            else :\n",
    "                loss = tf.math.add(loss, loss_OneCell)\n",
    "        \n",
    "        if batch_loss == 0 :\n",
    "            batch_loss = tf.identity(loss)\n",
    "        else :\n",
    "            batch_loss = tf.math.add(batch_loss, loss)\n",
    "        \n",
    "    # 배치에 대한 loss 구하기\n",
    "    count = tf.Variable(float(count))\n",
    "    batch_loss = tf.math.divide(batch_loss, count)\n",
    "    \n",
    "    return batch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력된 bbox 정보를 사진에 출력할 수 있게 처리\n",
    "def process_bbox(x, y, bbox, image_size, classes_score, Classes_inDataSet) : \n",
    "    # size 처리\n",
    "    bbox_x = ((32.0 * x) + (bbox[0] * 32.0)) * (image_size[0]/224.0) # 예를 들어 x = 0이면 0~32사이에 중점의 x좌표가 존재\n",
    "    bbox_y = ((32.0 * y) + (bbox[1] * 32.0)) * (image_size[1]/224.0) # 예를 들어 x = 0이면 0~32사이에 중점의 x좌표가 존재\n",
    "    bbox_w = bbox[2] * image_size[0] # 전체 이미지 대비 백분위\n",
    "    bbox_h = bbox[3] * image_size[1] # 전체 이미지 대비 백분위\n",
    "    \n",
    "    min_x = int(bbox_x - bbox_w/2)\n",
    "    min_y = int(bbox_y - bbox_h/2)\n",
    "    max_x = int(bbox_x + bbox_w/2)\n",
    "    max_y = int(bbox_y + bbox_h/2)\n",
    "    \n",
    "    #print(classes_score)\n",
    "    idx_class_highest_score = np.argmax(classes_score)\n",
    "    #print('가장 높은 스코어 값 확인', idx_class_highest_score)\n",
    "    #print(Classes_inDataSet)\n",
    "    class_highest_score = classes_score[idx_class_highest_score] # 가장 높은 class score\n",
    "    \n",
    "    class_highest_score_name = Classes_inDataSet[idx_class_highest_score] # 가장 높은 score를 가진 class의 이름\n",
    "    \n",
    "    output_bbox = [min_x, min_y, max_x, max_y, class_highest_score, class_highest_score_name]\n",
    "\n",
    "    return output_bbox # [x, y, w, h, class_highest_score, class_highest_score_name]로 구성된 list출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매우 간단하게 구현된 nms\n",
    "def nms(bbox_list) : \n",
    "    nms_bbox_list = []\n",
    "    for i in range(0, len(bbox_list)) :\n",
    "        \n",
    "        if bbox_list[i][4] > 0.4 : # class score가 0.5넘기는 것만 출력하기\n",
    "            nms_bbox_list.append(bbox_list[i])\n",
    "    \n",
    "    return nms_bbox_list\n",
    "\n",
    "def get_YOLO_output(YOLO, Image_path, Classes_inDataSet) : \n",
    "    print('이미지 파일 확인' + Image_path)\n",
    "    image_cv = cv2.imread(Image_path)\n",
    "    height, width,_ = image_cv.shape # 이미지 원래 사이즈를 얻는다. [w, h]\n",
    "    image_size = [width, height]\n",
    "    \n",
    "    image_cv = cv2.resize(image_cv, (224, 224))/255\n",
    "    image_cv = np.expand_dims(image_cv, axis = 0)\n",
    "    image_cv = image_cv.astype('float32')\n",
    "    # 계산의 간편함을 위해 numpy array로 변환. [1,7,7,30]으로 나오기 때문에 [7,7,30]으로 변경\n",
    "    YOLO_output = YOLO(image_cv)[0].numpy() \n",
    "    bbox_list = []\n",
    "    for y in range(0, 7) :\n",
    "        for x in range(0, 7) :\n",
    "            # bbox에 있는 20개의 클래스 스코어\n",
    "            bbox1_class_score = YOLO_output[y][x][10:] * YOLO_output[y][x][4]\n",
    "            bbox2_class_score = YOLO_output[y][x][10:] * YOLO_output[y][x][9]\n",
    "            # bbox의 사이즈\n",
    "            bbox1 = YOLO_output[y][x][0:4]\n",
    "            bbox2 = YOLO_output[y][x][5:9]   \n",
    "            # 24 -> 6(box info + 가장 높게 나온 클래스 prob + 가장 높게 나온 클래스의 idx)개로 처리\n",
    "            # opencv는 min_x, min_y, max_x, max_y를 원하니 x, y, w, h를 min, max 좌표로 변환\n",
    "            process_bbox1 = process_bbox(x, y, bbox1, image_size, bbox1_class_score, Classes_inDataSet)\n",
    "            process_bbox2 = process_bbox(x, y, bbox2, image_size, bbox2_class_score, Classes_inDataSet)\n",
    "            bbox_list.append(process_bbox1)\n",
    "            bbox_list.append(process_bbox2)\n",
    "    \n",
    "    nms_bbox_list = nms(bbox_list)\n",
    "    print(nms_bbox_list)\n",
    "    # nms_bbox_list = bbox_list\n",
    "    \n",
    "    im_read = cv2.imread(Image_path)\n",
    "    for i in range(0, len(nms_bbox_list)) :\n",
    "        # rectangle함수를 위해 필요한 '박스의 최소 x,y 좌표'와 '박스의 최대 x,y좌표'리스트를 생성한다. \n",
    "        min_box = (nms_bbox_list[i][0], nms_bbox_list[i][1])\n",
    "        max_box = (nms_bbox_list[i][2], nms_bbox_list[i][3])\n",
    "        # 출력하기\n",
    "        cv2.rectangle(im_read, min_box, max_box, (0, 255, 0), 1) # 박스 그리기\n",
    "#         show_str = nms_bbox_list[i][5] + \" : \" + str(nms_bbox_list[i][4])\n",
    "        show_str = nms_bbox_list[i][5] # 객체 이름만 표시\n",
    "        # 글자 넣어주기\n",
    "        text_min_box = (nms_bbox_list[i][0] + 2, nms_bbox_list[i][1] - 10)\n",
    "        text_max_box = (nms_bbox_list[i][2], nms_bbox_list[i][1])\n",
    "        cv2.rectangle(im_read, text_min_box, text_max_box, (0, 255, 0), -1) # 박스 그리기    \n",
    "        cv2.putText(im_read, show_str, (min_box[0] + 2, min_box[1] - 1), cv2.FONT_HERSHEY_PLAIN, 0.7, (0,0,0), 1)\n",
    "    \n",
    "    cv2.imwrite('output.jpg', im_read)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1863\n",
      "1863\n",
      "20\n",
      "이미지 파일 확인C:/chan/Pothole.v1-raw.voc//test/JPEGImages/img-522_jpg.rf.19bb1d8b2dbde293dc2db61b5beb29db.jpg\n",
      "[[118, 87, 351, 227, 0.57922065, 'pothole'], [203, 94, 393, 213, 0.41276252, 'person'], [214, 126, 377, 260, 0.46431777, 'person']]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "    \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum = 0.9)\n",
    "YOLO = load_model('yolo_best.h5', compile=False)\n",
    "YOLO.compile(loss = yolo_multitask_loss, optimizer=optimizer, run_eagerly=True)\n",
    "\n",
    "# 파일 경로\n",
    "train_x_path = \"C:/chan/Pothole.v1-raw.voc/JPEGImages\"\n",
    "train_y_path = \"C:/chan/Pothole.v1-raw.voc/Annotations\"\n",
    "\n",
    "test_x_path = \"C:/chan/Pothole.v1-raw.voc//test/JPEGImages\"\n",
    "test_y_path = \"C:/chan/Pothole.v1-raw.voc/test/Annotations\"\n",
    "#test_x_path = 'C:/Users/user/Downloads/imageset/VOCdevkit/VOC2012/Test/JPEGImages'\n",
    "#test_y_path = 'C:/Users/user/Downloads/imageset/VOCdevkit/VOC2012/Test/Annotations'\n",
    "\n",
    "# 파일 경로 휙득\n",
    "image_file_path_list = sorted([x for x in glob(train_x_path + '/**')])\n",
    "xml_file_path_list = sorted([x for x in glob(train_y_path + '/**')])\n",
    "print(len(image_file_path_list))\n",
    "print(len(xml_file_path_list))\n",
    "test_image_file_path_list = sorted([x for x in glob(test_x_path + '/**')])\n",
    "test_xml_file_path_list = sorted([x for x in glob(test_y_path + '/**')])\n",
    "\n",
    "Classes_inDataSet = get_Classes_inImage(xml_file_path_list)\n",
    "print(len(Classes_inDataSet))\n",
    "\n",
    "# 이미지 파일 경로\n",
    "image_path = 'C:/chan/Pothole.v1-raw.voc//test/JPEGImages/img-522_jpg.rf.19bb1d8b2dbde293dc2db61b5beb29db.jpg'\n",
    "\n",
    "# get_YOLO_output 함수 호출\n",
    "get_YOLO_output(YOLO, image_path, Classes_inDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# image_path = 'C:/chan/Pothole.v1-raw.voc/JPEGImages'\n",
    "# annotation_path = 'C:/chan/Pothole.v1-raw.voc/Annotations'\n",
    "\n",
    "# # 이미지 파일 이름 추출\n",
    "# image_files = os.listdir(image_path)\n",
    "# image_names = [os.path.splitext(file)[0] for file in image_files]\n",
    "\n",
    "# # Annotations 경로에서 동일한 이름의 XML 파일 삭제\n",
    "# for image_name in image_names:\n",
    "#     xml_file = os.path.join(annotation_path, f\"{image_name}.xml\")\n",
    "    \n",
    "#     if os.path.exists(xml_file):\n",
    "#         os.remove(xml_file)\n",
    "#         print(f\"Deleted XML file: {xml_file}\")\n",
    "#     else:\n",
    "#         print(f\"XML file not found: {xml_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# annotations_path = 'C:/chan/Pothole.v1-raw.voc/Annotations'\n",
    "# jpeg_images_path = 'C:/chan/Pothole.v1-raw.voc/JPEGImages'\n",
    "\n",
    "# annotations_files = os.listdir(annotations_path)\n",
    "# jpeg_images_files = os.listdir(jpeg_images_path)\n",
    "\n",
    "# annotations_count = len(annotations_files)\n",
    "# jpeg_images_count = len(jpeg_images_files)\n",
    "\n",
    "# if annotations_count != jpeg_images_count:\n",
    "#     print(\"개수가 다른 파일이 존재합니다.\")\n",
    "#     missing_files = []\n",
    "\n",
    "#     # Annotations 경로에서 파일 이름 추출\n",
    "#     annotations_names = [os.path.splitext(file)[0] for file in annotations_files]\n",
    "\n",
    "#     # JPEGImages 경로에서 파일 이름 추출\n",
    "#     jpeg_images_names = [os.path.splitext(file)[0] for file in jpeg_images_files]\n",
    "\n",
    "#     # Annotations에는 있지만 JPEGImages에는 없는 파일 찾기\n",
    "#     for name in annotations_names:\n",
    "#         if name not in jpeg_images_names:\n",
    "#             missing_files.append(name)\n",
    "\n",
    "#     print(f\"Annotations 개수: {annotations_count}\")\n",
    "#     print(f\"JPEGImages 개수: {jpeg_images_count}\")\n",
    "#     print(\"개수가 다른 파일 목록:\")\n",
    "#     for file in missing_files:\n",
    "#         print(file)\n",
    "# else:\n",
    "#     print(\"개수가 일치하는 파일입니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# jpeg_images_path = 'C:/chan/Pothole.v1-raw.voc/JPEGImages'\n",
    "# annotations_path = 'C:/chan/Pothole.v1-raw.voc/Annotations'\n",
    "\n",
    "# jpeg_images_files = os.listdir(jpeg_images_path)\n",
    "# annotations_files = os.listdir(annotations_path)\n",
    "\n",
    "# different_files = []\n",
    "\n",
    "# for jpeg_file in jpeg_images_files:\n",
    "#     annotation_file = os.path.splitext(jpeg_file)[0] + \".xml\"\n",
    "#     if annotation_file not in annotations_files:\n",
    "#         different_files.append(jpeg_file)\n",
    "\n",
    "# for annotation_file in annotations_files:\n",
    "#     jpeg_file = os.path.splitext(annotation_file)[0] + \".jpg\"\n",
    "#     if jpeg_file not in jpeg_images_files:\n",
    "#         different_files.append(annotation_file)\n",
    "\n",
    "# print(\"다른 파일 이름 목록:\")\n",
    "# for file in different_files:\n",
    "#     print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def get_classes_in_image(xml_file_path):\n",
    "    classes_in_image = []\n",
    "\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for obj in root.findall(\"object\"):\n",
    "        name = obj.find(\"name\").text\n",
    "        classes_in_image.append(name)\n",
    "\n",
    "    return classes_in_image\n",
    "\n",
    "# 웹캠 초기화\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # 웹캠에서 프레임 읽기\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # 프레임 처리\n",
    "    # 여기에 객체 검출 모델을 적용하여 객체 검출 수행\n",
    "\n",
    "    # 결과를 화면에 표시\n",
    "    cv2.imshow(\"Real-time Object Detection\", frame)\n",
    "\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# 웹캠 해제 및 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 웹캠 영상 읽기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 프레임 속도 설정\n",
    "cap.set(cv2.CAP_PROP_FPS, 3)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # yolo 처리 작업\n",
    "    cv2.imwrite(filename='frame1.jpg',img=frame)\n",
    "    get_YOLO_output(net, frame, Classes_inDataSet,name='frame0.jpg')\n",
    "    # 결과 영상 출력\n",
    "    cv2.imshow(\"Webcam\", frame)\n",
    "    print(frame.shape)\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 종료 시 리소스 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.78px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
